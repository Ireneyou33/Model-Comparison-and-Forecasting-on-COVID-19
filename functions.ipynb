{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ireneyou33/Model-Comparison-and-Forecasting-on-COVID-19/blob/master/functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es50bIdvPDDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !echo %cd%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKimBPyBPDDM",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb690964-095c-49b1-a8be-08da0d40ae0a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets.widgets import interact, IntSlider, FloatSlider, Layout\n",
        "import datetime as dt\n",
        "from tensorflow.python.keras.layers import Dense, LSTM\n",
        "from tensorflow.python.keras import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from datetime import datetime, timedelta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ok7V4q_PDDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_conf=pd.read_csv(r\"C:\\Users\\hp\\COVID-19\\Confirmed.csv\")\n",
        "df_death=pd.read_csv(r\"C:\\Users\\hp\\COVID-19\\Deaths.csv\")\n",
        "df_recover=pd.read_csv(r\"C:\\Users\\hp\\COVID-19\\Recovered.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gpAdGAPDDT",
        "colab_type": "code",
        "colab": {},
        "outputId": "82bf81ce-d933-45b5-dd64-e1c8e3d30d0e"
      },
      "source": [
        "df_conf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Province/State</th>\n",
              "      <th>Country/Region</th>\n",
              "      <th>Lat</th>\n",
              "      <th>Long</th>\n",
              "      <th>1/22/20</th>\n",
              "      <th>1/23/20</th>\n",
              "      <th>1/24/20</th>\n",
              "      <th>1/25/20</th>\n",
              "      <th>1/26/20</th>\n",
              "      <th>1/27/20</th>\n",
              "      <th>...</th>\n",
              "      <th>6/19/20</th>\n",
              "      <th>6/20/20</th>\n",
              "      <th>6/21/20</th>\n",
              "      <th>6/22/20</th>\n",
              "      <th>6/23/20</th>\n",
              "      <th>6/24/20</th>\n",
              "      <th>6/25/20</th>\n",
              "      <th>6/26/20</th>\n",
              "      <th>6/27/20</th>\n",
              "      <th>6/28/20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0000</td>\n",
              "      <td>65.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>27878</td>\n",
              "      <td>28424</td>\n",
              "      <td>28833</td>\n",
              "      <td>29157</td>\n",
              "      <td>29481</td>\n",
              "      <td>29640</td>\n",
              "      <td>30175</td>\n",
              "      <td>30451</td>\n",
              "      <td>30616</td>\n",
              "      <td>30967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Albania</td>\n",
              "      <td>41.1533</td>\n",
              "      <td>20.1683</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1838</td>\n",
              "      <td>1891</td>\n",
              "      <td>1962</td>\n",
              "      <td>1995</td>\n",
              "      <td>2047</td>\n",
              "      <td>2114</td>\n",
              "      <td>2192</td>\n",
              "      <td>2269</td>\n",
              "      <td>2330</td>\n",
              "      <td>2402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>28.0339</td>\n",
              "      <td>1.6596</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>11504</td>\n",
              "      <td>11631</td>\n",
              "      <td>11771</td>\n",
              "      <td>11920</td>\n",
              "      <td>12076</td>\n",
              "      <td>12248</td>\n",
              "      <td>12445</td>\n",
              "      <td>12685</td>\n",
              "      <td>12968</td>\n",
              "      <td>13273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>42.5063</td>\n",
              "      <td>1.5218</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "      <td>855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Angola</td>\n",
              "      <td>-11.2027</td>\n",
              "      <td>17.8739</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>183</td>\n",
              "      <td>186</td>\n",
              "      <td>189</td>\n",
              "      <td>197</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>259</td>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Province/State Country/Region      Lat     Long  1/22/20  1/23/20  1/24/20  \\\n",
              "0            NaN    Afghanistan  33.0000  65.0000        0        0        0   \n",
              "1            NaN        Albania  41.1533  20.1683        0        0        0   \n",
              "2            NaN        Algeria  28.0339   1.6596        0        0        0   \n",
              "3            NaN        Andorra  42.5063   1.5218        0        0        0   \n",
              "4            NaN         Angola -11.2027  17.8739        0        0        0   \n",
              "\n",
              "   1/25/20  1/26/20  1/27/20   ...     6/19/20  6/20/20  6/21/20  6/22/20  \\\n",
              "0        0        0        0   ...       27878    28424    28833    29157   \n",
              "1        0        0        0   ...        1838     1891     1962     1995   \n",
              "2        0        0        0   ...       11504    11631    11771    11920   \n",
              "3        0        0        0   ...         855      855      855      855   \n",
              "4        0        0        0   ...         172      176      183      186   \n",
              "\n",
              "   6/23/20  6/24/20  6/25/20  6/26/20  6/27/20  6/28/20  \n",
              "0    29481    29640    30175    30451    30616    30967  \n",
              "1     2047     2114     2192     2269     2330     2402  \n",
              "2    12076    12248    12445    12685    12968    13273  \n",
              "3      855      855      855      855      855      855  \n",
              "4      189      197      212      212      259      267  \n",
              "\n",
              "[5 rows x 163 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__lp9KKOPDDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the world class dataframe\n",
        "def worldclass_dataframe(dataframe):\n",
        "    date=dataframe.columns[4:]\n",
        "    for i in range(len(date)):\n",
        "        date.values[i]=pd.to_datetime(date.values[i], format=\"%m/%d/%y\")\n",
        "    world=dataframe.sum(axis=0, skipna=True)\n",
        "    worldclass=world.iloc[2:,]\n",
        "    arr=np.array(worldclass)\n",
        "    new_df=pd.DataFrame([arr],columns=date)\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD6n6EUuPDDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_regioncase(dataframe, region, region_level=\"county\"):\n",
        "    # region: county, region or outside China\n",
        "    if region_level==\"county\":\n",
        "        df_return=dataframe[dataframe[\"Country/Region\"]==region].iloc[:,4:]\n",
        "    elif region_level==\"province\":\n",
        "        df_return=dataframe[dataframe[\"Province/State\"]==region].iloc[:,4:]\n",
        "    else:\n",
        "        df_return=dataframe[dataframe[\"Country/Region\"]!=region].iloc[:,4:]\n",
        "    reg=df_return.sum(axis=0, skipna=True)\n",
        "    arr=np.array(reg)\n",
        "    date=df_return.columns\n",
        "    for i in range(len(date)):\n",
        "        date.values[i]=pd.to_datetime(date.values[i], format=\"%m/%d/%y\")\n",
        "    new_df=pd.DataFrame([arr],columns=date)\n",
        "    return new_df, arr, date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9bzDmqxPDDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def train_test(data, split_index):\n",
        "    trainset=data.iloc[:, :split_index]\n",
        "    testset=data.iloc[:, split_index:]\n",
        "    return trainset, testset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXtc3svBPDDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def WindowSlider(data, w=1, r=1):\n",
        "  #w: window size\n",
        "  #r: response size\n",
        "\n",
        "    cols=len(list(data))\n",
        "    l=cols-(w+r)+1\n",
        "    df = pd.DataFrame(np.zeros(shape=(l, w+w+2*r)))\n",
        "\n",
        "    for m in range(l):\n",
        "        slices=np.array([])\n",
        "        delta_t=[]\n",
        "        num_confirm=[]\n",
        "\n",
        "        for i in range(w):\n",
        "            i+=m\n",
        "            delta=data.columns[i]-start_date\n",
        "            delta=delta.floor('d').days\n",
        "            delta_t.append(delta)\n",
        "            num_confirm.append(data.iloc[0,i])\n",
        "\n",
        "        y_delta=data.columns[m+w+r-1]-start_date\n",
        "        y_delta=y_delta.floor('d').days\n",
        "        y_delta=np.array(y_delta).reshape(1,)\n",
        "        y=data.iloc[0,m+w+r-1]\n",
        "        y=np.array(y).reshape(1,)\n",
        "\n",
        "        slices=np.concatenate((slices, delta_t, num_confirm))\n",
        "        slices=np.concatenate((slices, y_delta, y))\n",
        "\n",
        "        df.iloc[m,:]=slices\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEMD40zzPDDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_colnames(data, w=1, r=1):\n",
        "    delta_names=[]\n",
        "    x_names=[]\n",
        "    for i in range(w):\n",
        "        delta_names.append('∆t' + ('(%d)' % i))\n",
        "        x_names.append('x'+ ('%d' % i))\n",
        "    col_names=delta_names+x_names\n",
        "    l=w+r-1\n",
        "    col_names.append('∆t' + ('(%d)' % l))\n",
        "    col_names.append('y')\n",
        "    return col_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgN59Rt-PDDu",
        "colab_type": "text"
      },
      "source": [
        "### Daily Bar Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9BgFVIPPDDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def daily_bar_plot(dataframe, title, c=None):\n",
        "    daily_df = dataframe.copy()\n",
        "    length=dataframe.shape[1]\n",
        "    for i in range(length-1):\n",
        "        daily_df.iloc[0,i+1]=dataframe.iloc[0,i+1]-dataframe.iloc[0,i]\n",
        "    daily_df.T.plot.bar(title=title, figsize=(25,10), legend=False, color=c)\n",
        "    return daily_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlj80GNBPDDx",
        "colab_type": "text"
      },
      "source": [
        "### Barh Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YKgn-x5PDDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def barh_plot(dataframe, title, country=True, c=None):\n",
        "    df=dataframe.iloc[:,[1,-1]]\n",
        "    if country:\n",
        "        sum_region = df.groupby(['Country/Region']).sum()\n",
        "    else:\n",
        "        print(\"Not country level\")\n",
        "    sum_region.columns=[\"date\"]\n",
        "    sum_region=sum_region.sort_values(\"date\",ascending=False)\n",
        "    new_df=sum_region.head(n=20)\n",
        "    ax = new_df.plot.barh(color=c)\n",
        "    ax.set_title(title)\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgrurUW4PDD1",
        "colab_type": "text"
      },
      "source": [
        "### Pie Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToYqgT97PDD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pie_plot(dataframe, stage, title, inplace=False):\n",
        "    # stage = \"Confirmed\", \"Deaths\", \"Recovered\"\n",
        "    dataframe2=dataframe.copy()\n",
        "    dataframe2.reset_index(inplace=inplace)\n",
        "    dataframe2.columns=[\"Country\",stage]\n",
        "    region=np.array(dataframe2.index.values)\n",
        "    values=np.array(dataframe2.iloc[:,0])\n",
        "    if stage == \"Confirmed\":\n",
        "        fig = px.pie(dataframe2, names= 'Country', values=stage,title=title, color_discrete_sequence=px.colors.sequential.Blues)\n",
        "        fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "        fig.show()\n",
        "    elif stage == \"Deaths\":\n",
        "        fig = px.pie(dataframe2, names= 'Country', values=stage,title=title, color_discrete_sequence=px.colors.sequential.RdBu)\n",
        "        fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "        fig.show()\n",
        "    elif stage == \"Recovered\":\n",
        "        fig = px.pie(dataframe2, names= 'Country', values=stage,title=title, color_discrete_sequence=px.colors.sequential.Greens)\n",
        "        fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "        fig.show()\n",
        "    else:\n",
        "        print(\"Oooops Undefined Stage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn_vPrFvPDD4",
        "colab_type": "text"
      },
      "source": [
        "## NeuralNets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_VW1OdTPDD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_traintest(dataframe, idx, w=1, r=1, wfv=False):\n",
        "    if wfv==True:\n",
        "        trainset=dataframe.iloc[:, :idx]\n",
        "        testset=dataframe.iloc[:, idx:idx+10] # fixed test size = 10\n",
        "    else:\n",
        "        trainset, testset = train_test(dataframe, split_index=idx)\n",
        "    if w == 1:\n",
        "        train = WindowSlider(trainset, w=w, r=1)\n",
        "        X_train = train[1]\n",
        "        Y_train = train[3]\n",
        "        test = WindowSlider(testset, w=w, r=1)\n",
        "        X_test = test[1]\n",
        "        Y_test = test[3]\n",
        "    elif w == 3:\n",
        "        train = WindowSlider(trainset, w=w, r=1)\n",
        "        X_train = train[[3,4,5]]\n",
        "        Y_train = train[[7]]\n",
        "        test = WindowSlider(testset, w=w, r=1)\n",
        "        X_test = test[[3,4,5]]\n",
        "        Y_test = test[[7]]\n",
        "    elif w == 5:\n",
        "        train = WindowSlider(trainset, w=w, r=1)\n",
        "        X_train = train[[5,6,7,8,9]]\n",
        "        Y_train = train[[11]]\n",
        "        test = WindowSlider(testset, w=w, r=1)\n",
        "        X_test = test[[5,6,7,8,9]]\n",
        "        Y_test = test[[11]]\n",
        "    elif w == 7:\n",
        "        train = WindowSlider(trainset, w=w, r=1)\n",
        "        X_train = train[[7,8,9,10,11,12,13]]\n",
        "        Y_train = train[[15]]\n",
        "        test = WindowSlider(testset, w=w, r=1)\n",
        "        X_test = test[[7,8,9,10,11,12,13]]\n",
        "        Y_test = test[[15]]\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXKTxtLUPDD6",
        "colab_type": "text"
      },
      "source": [
        "## Average R0 dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VpTGq1RPDD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ave_R0(conf_dataframe, recov_dataframe, death_dataframe, ave_days=7):\n",
        "  # Parameters estimation\n",
        "    slope=[]\n",
        "    gamma=[]\n",
        "    mu=[]\n",
        "    for i in range(0, conf_dataframe.shape[1]-1):\n",
        "        s=np.log(conf_dataframe.iloc[0,i+1])-np.log(conf_dataframe.iloc[0,i])\n",
        "        g=(recov_dataframe.iloc[0,i+1]-recov_dataframe.iloc[0,i])/conf_dataframe.iloc[0,i]\n",
        "        m=(death_dataframe.iloc[0,i+1]-death_dataframe.iloc[0,i])/conf_dataframe.iloc[0,i]\n",
        "        slope.append(s)\n",
        "        gamma.append(g)\n",
        "        mu.append(m)\n",
        "    beta=np.array(slope)+np.array(gamma)+np.array(mu)\n",
        "    # Average R0\n",
        "    R0=[]\n",
        "    for i in range(len(beta)):\n",
        "        if gamma[i]+mu[i] != 0:\n",
        "            R0.append(beta[i]/(gamma[i]+mu[i]))\n",
        "        else:\n",
        "            R0.append(0)\n",
        "    ave_R0=[]\n",
        "    ave_R0+=[sum(R0[i:i+ave_days])/ave_days for i in range(len(R0)-ave_days+1)]\n",
        "    # Region average R0 dataframe\n",
        "    arr=np.array(ave_R0)\n",
        "    date=conf_dataframe.columns[:-ave_days]\n",
        "    for i in range(len(date)):\n",
        "        date.values[i]=pd.to_datetime(date.values[i], format=\"%m/%d/%y\")\n",
        "    df_region_aveR0=pd.DataFrame([arr],columns=date)\n",
        "    return df_region_aveR0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "allXpZwrPDD-",
        "colab_type": "text"
      },
      "source": [
        "## Use LSTM to model R0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGcH_GazPDD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_traintestdata(dataframe, w=1, r=1, lockdown_date=1):\n",
        "    if w == 3:\n",
        "        start_date = pd.to_datetime(dataframe.columns[lockdown_date], format=\"%m/%d/%y\")\n",
        "        training = WindowSlider(dataframe.iloc[:,lockdown_date:], w)\n",
        "        x_train = training[[3,4,5]]\n",
        "        y_train = training[[7]]\n",
        "    elif w ==1:\n",
        "        start_date = pd.to_datetime(dataframe.columns[lockdown_date], format=\"%m/%d/%y\")\n",
        "        training = WindowSlider(dataframe.iloc[:,lockdown_date:], w)\n",
        "        x_train = training[[1]]\n",
        "        y_train = training[[3]]\n",
        "    return x_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtwCaM-fPDEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_r0_model(dataframe, w=1, r=1, lockdown_date=1):\n",
        "    x_train, y_train = get_traintestdata(dataframe)\n",
        "    x = np.array(x_train)\n",
        "    x = x.astype(int)\n",
        "    X = x.reshape((x.shape[0], x.shape[1], r))\n",
        "\n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, activation='relu', input_shape=(w, r)))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    model.fit(X, y_train, epochs=200, verbose=0)\n",
        "    if w == 3:\n",
        "        model.save('HubeiR0_w3.h5')\n",
        "    elif w == 1:\n",
        "        model.save('HubeiR0_w1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpfa8svqPDEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def R0_forecast(df, model, forecast_days=10, w=3, r=1):\n",
        "    df_test = df.copy()\n",
        "    for i in range(forecast_days):\n",
        "        a = df_test.columns[-1] + timedelta(days=1)\n",
        "        df_test[a] = np.nan\n",
        "        df_test[a].iloc[0] = df_test.iloc[1,-2]\n",
        "        testing = WindowSlider(df_test, w)\n",
        "        if w == 3:\n",
        "            x_test = testing[[3,4,5]]\n",
        "            y_test = testing[[7]]\n",
        "        elif w == 1:\n",
        "            x_test = testing[[1]]\n",
        "            y_test = testing[[3]]\n",
        "        x_test = np.array(x_test)\n",
        "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], r))\n",
        "        y_pred = model.predict(x_test, verbose=0)\n",
        "        df_test.iloc[-1,-1]=y_pred[-1]\n",
        "    return df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2EloF5IPDEG",
        "colab_type": "text"
      },
      "source": [
        "Walk Forward Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAstm-htPDEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def walk_forward_vali(dataframe, w=1, idx=30):\n",
        "    train_RMSE=[]\n",
        "    test_RMSE=[]\n",
        "    train_size=[]\n",
        "    while idx < dataframe.shape[1]-10:\n",
        "        X_tr, Y_tr, X_te, Y_te = get_traintest(dataframe, idx, w=w, r=1, wfv=True)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(8, input_dim=w, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "        model.fit(X_tr, Y_tr, epochs=200, batch_size=2, verbose=0)\n",
        "        trainScore = model.evaluate(X_tr, Y_tr, verbose=0)\n",
        "        train_RMSE.append(math.sqrt(trainScore))\n",
        "        testScore = model.evaluate(X_te, Y_te, verbose=0)\n",
        "        test_RMSE.append(math.sqrt(testScore))\n",
        "        train_size.append(idx)\n",
        "        idx+=10 # Each time increase training size by 10\n",
        "    return train_RMSE, test_RMSE, train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czTCcMkQPDEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def walk_forward_vali_lstm(dataframe, w=1, idx=30):\n",
        "    train_RMSE=[]\n",
        "    test_RMSE=[]\n",
        "    train_size=[]\n",
        "    while idx < dataframe.shape[1]-10:\n",
        "        X_tr, Y_tr, X_te, Y_te = get_traintest(dataframe, idx, w=w, r=1, wfv=True)\n",
        "        if w ==1:\n",
        "            X_tr = reshape_func(X_tr, r=1)\n",
        "            X_te = reshape_func(X_te, r=1)\n",
        "        else:\n",
        "            X_tr = reshape_func(X_tr,shape=w, r=1)\n",
        "            X_te = reshape_func(X_te, shape=w, r=1)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(LSTM(50, activation='relu', input_shape=(w, r)))\n",
        "        model.add(Dense(1))\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        model.fit(X_tr, Y_tr, epochs=200, batch_size=2, verbose=0)\n",
        "        trainScore = model.evaluate(X_tr, Y_tr, verbose=0)\n",
        "        train_RMSE.append(math.sqrt(trainScore))\n",
        "        testScore = model.evaluate(X_te, Y_te, verbose=0)\n",
        "        test_RMSE.append(math.sqrt(testScore))\n",
        "        train_size.append(idx)\n",
        "        idx+=10 # Each time increase training size by 10\n",
        "    return train_RMSE, test_RMSE, train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYPXkH7PDEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmLJt_cLPDEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}